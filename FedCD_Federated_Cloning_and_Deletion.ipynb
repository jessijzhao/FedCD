{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedCD: Federated Cloning and Deletion",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessijzhao/FedCD/blob/master/FedCD_Federated_Cloning_and_Deletion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ttBYeclcLI"
      },
      "source": [
        "# **FedCD: Federated Cloning and Deletion**\n",
        "\n",
        "Jessica Zhao, Eric Lin, Kavya Kopparapu \n",
        "\n",
        "Presented at the 3rd International Workshop on Artificial Intelligence of Things\n",
        "in conjunction with the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2020).\n",
        "\n",
        "Utilizes handout code for federated learning with CIFAR-10 from CS 242: Computing at Scale (Spring 2020) by HT Kung.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5kLxSFZssRo"
      },
      "source": [
        "### **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8UpiDU4szfu"
      },
      "source": [
        "# setup parameters\n",
        "NUM_DEVICES = 30                                            # number of devices\n",
        "NUM_LABELS = 10                                             # number of labels\n",
        "NUM_TRAIN_PER_DEVICE = 5000                                 # number of training examples per device\n",
        "NUM_VALID_PER_DEVICE = NUM_TRAIN_PER_DEVICE // 3            # number of validation examples per device\n",
        "NUM_TEST_PER_DEVICE = 500                                   # number of test examples per device\n",
        "DISTRIBUTION = \"uniform\"                                    # data distribution\n",
        "assert (DISTRIBUTION in [\"uniform\", \"hypergeometric\"])\n",
        "\n",
        "# training parameters\n",
        "NUM_ROUNDS = 150                                            # number of training rounds\n",
        "NUM_LOCAL_EPOCHS = 3                                        # number of local epochs per device per round\n",
        "DEVICE_PCT = 0.5                                            # fraction of devices for each round\n",
        "DUPLICATE_MILESTONES = [2, 15, 25, 30]                      # training rounds at which to duplicate models, TODO reset\n",
        "THRESHOLD = 15                                              # number of rounds before finalizing a model\n",
        "\n",
        "# quantization parameters\n",
        "QUANTIZE = True                                             # whether to quantize models\n",
        "NBIT = 8                                                    # number of bits to quantize to\n",
        "\n",
        "# which model(s) to run\n",
        "RUN_FEDCD = True                                            # Federated Cloning and Deletion\n",
        "RUN_FEDAVG = True                                           # baseline federated learning algorithm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UvFA89jTuON"
      },
      "source": [
        "### **Setup Code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WL6HA_Lpe8"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DatasetSplit(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Returns a new dataset with the indexed items.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = [int(i) for i in idxs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, torch.tensor(label)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5_L6BhYif6h"
      },
      "source": [
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
        "               padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    \n",
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution neural net used as the model.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(3, 32),\n",
        "            conv_block(32, 32),\n",
        "            conv_block(32, 64, stride=2),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 128, stride=2),\n",
        "            conv_block(128, 128),\n",
        "            conv_block(128, 256),\n",
        "            conv_block(256, 256),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.model(x)\n",
        "        B, C, _, _ = h.shape\n",
        "        h = h.view(B, C)\n",
        "        return self.classifier(h)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx1GxV2j0iI"
      },
      "source": [
        "import statistics \n",
        "\n",
        "class Device():\n",
        "    \"\"\"\n",
        "    Each instance represents an edge device.\n",
        "    \"\"\"\n",
        "    def __init__(self, net, device_id, trainset, validset, testset, train_idxs, \n",
        "                 valid_idxs, test_idxs, bias, archetype, lr=0.1, milestones=[25, 50, 75], \n",
        "                 batch_size=128):\n",
        "\n",
        "        # training data\n",
        "        self.device_trainset = DatasetSplit(trainset, train_idxs)\n",
        "        self.trainloader = torch.utils.data.DataLoader(self.device_trainset,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True,\n",
        "                                                        num_workers=2)\n",
        "        # validation data\n",
        "        self.device_validset = DatasetSplit(validset, valid_idxs)\n",
        "        self.validloader = torch.utils.data.DataLoader(self.device_validset,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True,\n",
        "                                                        num_workers=2)\n",
        "        # test data\n",
        "        self.device_testset = DatasetSplit(testset, test_idxs)\n",
        "        self.testloader = torch.utils.data.DataLoader(self.device_testset,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True,\n",
        "                                                        num_workers=2)\n",
        "        \n",
        "        # initiate list of models with a single model\n",
        "        device_net = copy.deepcopy(net)\n",
        "        optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9,\n",
        "                                    weight_decay=5e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                         milestones=milestones,\n",
        "                                                         gamma=0.1)\n",
        "        self.nets = [{\n",
        "            'net': device_net,\n",
        "            'optimizer': optimizer,\n",
        "            'scheduler': scheduler,\n",
        "            'train_loss_tracker': [],\n",
        "            'train_acc_tracker': [],\n",
        "            'valid_loss_tracker': [],\n",
        "            'valid_acc_tracker': [],\n",
        "            'test_loss_tracker': [],\n",
        "            'test_acc_tracker': [],\n",
        "        }]\n",
        "        \n",
        "        # device id\n",
        "        self.idx = device_id\n",
        "\n",
        "        # rankings for each model, must sum to 1\n",
        "        self.ranking = [1.]\n",
        "\n",
        "        # whether a given model is active, in (1, 0)\n",
        "        self.active = [1] \n",
        "\n",
        "        # bias and archetype parameters\n",
        "        self.bias = bias              # fractions to represent a linear combination of archetypes\n",
        "        self.archetype = archetype    # list of possible archetypes\n",
        "    \n",
        "    def update_ranking(self, prune, removed=False, duplicate_model_id=-1, offset_rank=-1):\n",
        "        # number of standard deviations away for model deletion cutoff\n",
        "        zero_threshold = 1 \n",
        "\n",
        "        if len(self.nets) > 1:\n",
        "            metrics = []\n",
        "            for i in range(len(self.nets)):\n",
        "                if len(self.nets[i]['valid_acc_tracker']) > 0:\n",
        "                    rank = self.nets[i]['valid_acc_tracker'][-1]\n",
        "                    if len(self.nets[i]['valid_acc_tracker']) >= 3:\n",
        "                        rank = ((self.nets[i]['valid_acc_tracker'][-1]\n",
        "                                 + self.nets[i]['valid_acc_tracker'][-2]\n",
        "                                 + self.nets[i]['valid_acc_tracker'][-3]) /3)\n",
        "                    if duplicate_model_id == i and offset_rank != -1:\n",
        "                        # Heavily rank the devices that are underperforming for new models and vice versa\n",
        "                        rank = offset_rank      \n",
        "                    if rank == 0:\n",
        "                        rank += 0.001\n",
        "                    metrics.append(rank)\n",
        "                else:\n",
        "                    metrics.append(50)\n",
        "            \n",
        "            # if we added more models, add active trackers for them\n",
        "            while len(self.nets) != len(self.active):\n",
        "                self.active.append(1)\n",
        "            #  Auto-set a model as inactive if it was already removed\n",
        "            if removed:       \n",
        "                self.active[duplicate_model_id] = 0\n",
        "\n",
        "            # normalization first time (with self.active)\n",
        "            self.ranking = [metrics[i]*self.active[i]/sum(metrics) for i in range(len(metrics))]\n",
        "\n",
        "            nonzero_elts = np.array(self.active).nonzero()[0]\n",
        "            nonzero_arr = []\n",
        "            for i in nonzero_elts:\n",
        "                nonzero_arr.append(self.ranking[i])\n",
        "            \n",
        "            # Remove models that are underperforming\n",
        "            if offset_rank == -1:   # only remove if not duplicating round\n",
        "                max_rank = max(self.ranking)\n",
        "                if len(nonzero_elts) > 1:\n",
        "                    std = statistics.stdev(nonzero_arr)\n",
        "                    mean = sum(nonzero_arr)/len(nonzero_arr)\n",
        "\n",
        "                    # remove models that are underperforming\n",
        "                    for j in range(len(self.ranking)):\n",
        "                        if self.active[j] != 0:\n",
        "                            if mean - self.ranking[j] > zero_threshold*std :\n",
        "                                self.ranking[j], self.active[j] = 0, 0\n",
        "                            elif len(self.ranking) > 3 and (self.ranking[j] * 10 < max_rank):\n",
        "                                self.ranking[j], self.active[j] = 0, 0\n",
        "\n",
        "            bool_ranking_below_zero = False\n",
        "            \n",
        "            # Add noise\n",
        "            noise = random.gauss(0, 0.01)\n",
        "            if len(nonzero_elts) == 1:\n",
        "                i = nonzero_elts[0]\n",
        "            else:\n",
        "                i = nonzero_elts[random.randint(0, len(nonzero_elts)-1)]\n",
        "                for j in range(len(self.ranking)):\n",
        "                    if j != i:\n",
        "                        self.ranking[j] -= noise/(len(nonzero_elts)-1)\n",
        "                        if self.ranking[j] < 0:\n",
        "                          bool_ranking_below_zero = True\n",
        "            \n",
        "            self.ranking[i] += noise\n",
        "            if self.ranking[i] < 0:\n",
        "                bool_ranking_below_zero = True\n",
        "\n",
        "            # normalize again\n",
        "            if bool_ranking_below_zero:\n",
        "                self.ranking = [self.ranking[i]-min(self.ranking) for i in range(len(self.ranking))]\n",
        "            self.ranking = [self.ranking[i]*self.active[i]/sum(self.ranking) for i in range(len(self.ranking))]\n",
        "\n",
        "            # finalize a model if applicable s\n",
        "            if prune and sum(self.active) == 2:\n",
        "                m1, m2 = [i for i in range(len(self.active)) if self.active[i] == 1 ]\n",
        "                # ensure that m1 is the better model\n",
        "                if self.ranking[m2] > self.ranking[m1]:\n",
        "                    m1, m2 = m2, m1\n",
        "                # if m1 is significantly better, deactivate m2\n",
        "                if self.ranking[m1] - self.ranking[m2] > 0.5:\n",
        "                    self.ranking[m1] = 1\n",
        "                    self.ranking[m2], self.active[m2] = 0, 0\n",
        "                    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpjaHzfA-0SF"
      },
      "source": [
        "class Analytics():\n",
        "    \"\"\"\n",
        "    Tracks and analyzes experimental data\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.per_device_accuracy = []\n",
        "\n",
        "    def update_per_device(self, per_device):\n",
        "        self.per_device_accuracy.append(per_device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qPw04ousTPV"
      },
      "source": [
        "def train(epoch, device, model_id):\n",
        "    device.nets[model_id]['net'].train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    dataset = device.device_trainset\n",
        "    dataloader = device.trainloader\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        device.nets[model_id]['optimizer'].zero_grad()\n",
        "        outputs = device.nets[model_id]['net'](inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        device.nets[model_id]['optimizer'].step()\n",
        "        train_loss += loss.item()\n",
        "        device.nets[model_id]['train_loss_tracker'].append(loss.item())\n",
        "        loss = train_loss / (batch_idx + 1)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "        dev_id = device.idx\n",
        "    test_loss = 0\n",
        "    outputs = [0]\n",
        "    device.nets[model_id]['train_acc_tracker'].append(acc)\n",
        "\n",
        "def validate(epoch, device, model_id):\n",
        "    device.nets[model_id]['net'].eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    dataset = device.device_validset\n",
        "    dataloader = device.validloader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = device.nets[model_id]['net'](inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            device.nets[model_id]['valid_loss_tracker'].append(loss.item())\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            loss = test_loss / (batch_idx + 1)\n",
        "            acc = 100.* correct / total\n",
        "        test_loss = 0\n",
        "        outputs = [0]\n",
        "    acc = 100.*correct/total\n",
        "    device.nets[model_id]['valid_acc_tracker'].append(acc)\n",
        "    device.nets[model_id]['net'].train()\n",
        "\n",
        "def test(epoch, device, model_id, dataset, dataloader=None, label_dict=None):\n",
        "    \"\"\"\n",
        "    Uses test set to evaluate performance.\n",
        "    \"\"\"\n",
        "    # turn the net into evaluaton mode\n",
        "    device.nets[model_id]['net'].eval()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = device.nets[model_id]['net'](inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()            \n",
        "            device.nets[model_id]['test_loss_tracker'].append(loss.item())\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            loss = test_loss / (batch_idx + 1)\n",
        "            acc = 100.* correct / total\n",
        "        test_loss = 0\n",
        "        outputs = [0]\n",
        "    acc = 100.*correct/total\n",
        "    device.nets[model_id]['test_acc_tracker'].append(acc)\n",
        "\n",
        "    device.nets[model_id]['net'].train()\n",
        "    return ('%.3f' % loss, '%.3f' % acc)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0fTWKg6hBY"
      },
      "source": [
        "def model_average_weight(devices, model_id):\n",
        "    '''\n",
        "    devices: list of devices\n",
        "    model_id: id of given model\n",
        "    \n",
        "    Returns the average of the weights of the given model taken over devices.\n",
        "    '''\n",
        "    d_id = 0\n",
        "    while d_id < len(devices) and devices[d_id].active[model_id] == 0:\n",
        "        d_id += 1\n",
        "\n",
        "    if d_id >= len(devices):\n",
        "        return None\n",
        "\n",
        "    # initialize a global tensor with the weights of the first device   \n",
        "    global_tensors = copy.deepcopy(devices[d_id].nets[model_id]['net'].state_dict()) \n",
        "    ranking_sum = devices[d_id].ranking[model_id]\n",
        "\n",
        "    #iterate over the remaining devices\n",
        "    for i in range(len(devices)):\n",
        "        if i == d_id:\n",
        "            #add the tensors together by the key they are indexed by\n",
        "            for j in global_tensors.keys(): \n",
        "                global_tensors[j] = global_tensors[j] * devices[d_id].ranking[model_id]\n",
        "        if devices[i].active[model_id] == 1:\n",
        "            # store the device and the state_dict for easier referencing\n",
        "            d = devices[i]\n",
        "            d_tensors = d.nets[model_id]['net'].state_dict()\n",
        "            # add the tensors together by the key they are indexed by\n",
        "            for j in global_tensors.keys(): \n",
        "                global_tensors[j] += (d_tensors[j] * d.ranking[model_id]).type_as(global_tensors[j])\n",
        "            ranking_sum += devices[i].ranking[model_id]\n",
        "\n",
        "    # average each tensor by the number of devices\n",
        "    for j in global_tensors.keys(): \n",
        "        global_tensors[j] = global_tensors[j]/float(ranking_sum)\n",
        "\n",
        "    return global_tensors"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd_92f6V8Qoq"
      },
      "source": [
        "#### **Create non-iid training and validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VajsGz0wiL05"
      },
      "source": [
        "# creates noniid TEST datasets for each group\n",
        "def gen_label_dict(dataset):\n",
        "    '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "\n",
        "    Returns a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22]\n",
        "        1: [0, 2, 4, ..., 583]\n",
        "        ...\n",
        "      }\n",
        "    '''\n",
        "    # label dict stores the indexes of the dataset examples that fall into the ith group of CIFAR\n",
        "    label_dict = {}\n",
        "\n",
        "    # assumes CIFAR with labels 0-9\n",
        "    for i in range(10): \n",
        "        label_dict[i] = []\n",
        "    for i in range(len(dataset)):\n",
        "        label = dataset[i][1]\n",
        "        label_dict[label].append(i)\n",
        "    return label_dict\n",
        "\n",
        "# creates noniid TRAINING and VALIDATION datasets for each group\n",
        "def data_sampler(dist, dataset, num_items_per_device, archetype, bias):\n",
        "    '''\n",
        "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
        "    num_items_per_device: how many samples to assign to each device\n",
        "    archetype: a dictionary of arrays representing the labels that is predominantly represented by this edge device\n",
        "        device index -> array of archetypes\n",
        "    bias: a dictionary of the percent of samples that are represented by the archetype\n",
        "        device index -> value from 0 to 1\n",
        "\n",
        "    Returns a dictionary of the following format:\n",
        "      {\n",
        "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
        "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
        "        ...\n",
        "      }\n",
        "    '''\n",
        "    assert (dist in [\"uniform\", \"hypergeometric\"])\n",
        "\n",
        "    label_dict = gen_label_dict(dataset)\n",
        "    result_dict = {}\n",
        "\n",
        "    if dist == \"uniform\":\n",
        "        for i in range(NUM_DEVICES):\n",
        "            bias_group = []\n",
        "            not_bias_group = []\n",
        "            archs = range(10)\n",
        "            for j in label_dict.keys():\n",
        "                if j in archetype[i]:\n",
        "                    bias_group += label_dict[j]\n",
        "                # two meta-archetypes\n",
        "                if archetype[i][0] in range(5): \n",
        "                    if j in range(5) and j != archetype[i][0]:\n",
        "                        not_bias_group += label_dict[j]\n",
        "                # two meta-archetypes\n",
        "                elif archetype[i][0] in range(5,10): \n",
        "                    if j in range(5,10) and j != archetype[i][0]:\n",
        "                        not_bias_group += label_dict[j]\n",
        "\n",
        "            exs = random.sample(bias_group, int(num_items_per_device*bias[i]))\n",
        "            exs.extend(random.sample(not_bias_group, num_items_per_device-int(num_items_per_device*bias[i])))\n",
        "            random.shuffle(exs)\n",
        "            result_dict[i] = exs\n",
        "        return result_dict\n",
        "\n",
        "    if dist == \"hypergeometric\":\n",
        "        rng = np.random.default_rng()\n",
        "        \n",
        "        for i in range(NUM_DEVICES):\n",
        "            N = 110\n",
        "            ngood = archetype[i][0]*20 + 5\n",
        "            nbad = N - ngood\n",
        "            nsamp = 10\n",
        "            classes = rng.hypergeometric(ngood, nbad, nsamp, num_items_per_device)\n",
        "            unique_elements, counts_elements = np.unique(classes, return_counts=True)\n",
        "\n",
        "            # how many examples from each label\n",
        "            counts = dict(zip(list(unique_elements), list(counts_elements)))\n",
        "            for j in range(10):\n",
        "                if j not in counts:\n",
        "                    counts[j] = 0\n",
        "\n",
        "            exs = []\n",
        "            for j in label_dict.keys():\n",
        "                exs.extend(random.sample(label_dict[j], counts[j]))\n",
        "\n",
        "            random.shuffle(exs)\n",
        "            result_dict[i] = exs\n",
        "        return result_dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0YiPamD627J"
      },
      "source": [
        "#### **Quantization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9KiAYyHS8VA"
      },
      "source": [
        "def quantizer(input, nbit):\n",
        "    '''    \n",
        "    input: a full precision tensor\n",
        "    nbit: the number of bits in the quantized representation\n",
        "    \n",
        "    Returns a quantized nbit version of a full precision tensor.\n",
        "    '''\n",
        "    scale_factor = 1 / (2**nbit -  1)\n",
        "\n",
        "    # scale input by inverse of scale_factor and round to nearest integer\n",
        "    output = input / scale_factor\n",
        "    output = torch.round(output)\n",
        "\n",
        "    # scale rounded output back and return\n",
        "    output *= scale_factor\n",
        "    return output\n",
        "\n",
        "\n",
        "def quantize_model(model, nbit):\n",
        "    '''\n",
        "    model: ConvNet model\n",
        "    nbit: the number of bits in the quantized representation\n",
        "\n",
        "    Quantizes the ConvNet model.\n",
        "    '''\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            m.weight.data, m.adaptive_scale = dorefa_g(m.weight, nbit)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data,_ = dorefa_g(m.bias, nbit, m.adaptive_scale)\n",
        "\n",
        "\n",
        "def dorefa_g(w, nbit, adaptive_scale=None):\n",
        "    '''\n",
        "    w: a floating-point weight tensor to quantize\n",
        "    nbit: the number of bits in the quantized representation\n",
        "    adaptive_scale: the maximum scale value. if None, it is set to be the\n",
        "                    absolute maximum value in w.\n",
        "    '''\n",
        "    if adaptive_scale is None:\n",
        "        adaptive_scale = torch.max(torch.abs(w))\n",
        "    \n",
        "    sigma = torch.rand(w.shape) - 0.5\n",
        "    noise = sigma / (2**nbit - 1)\n",
        "\n",
        "    # avoid type errors\n",
        "    noise = noise.type(w.type())\n",
        "    inp = w / (2*adaptive_scale) + 0.5 + noise\n",
        "    w_q = 2*adaptive_scale * (quantizer(inp, nbit) - 0.5)\n",
        "\n",
        "    return w_q, adaptive_scale"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXI0YBdC66-A"
      },
      "source": [
        "#### **Federated Learning Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrX_p7WJkZ5-"
      },
      "source": [
        "def federated_learning(algorithm=\"FedAvg\"):\n",
        "    \"\"\"\n",
        "    Runs federated learning algorithm (either FedCD or FedAvg).\n",
        "    \"\"\"\n",
        "    assert (algorithm in [\"FedCD\", \"FedAvg\"])\n",
        "\n",
        "    model_id_lst = [0]\n",
        "    prune = False\n",
        "    tracker = Analytics()\n",
        "\n",
        "    # create devices\n",
        "    devices = [Device(net, i, trainset, validset, testset, train_idxs[i], valid_idxs[i], \n",
        "                      test_idxs_device[i], devices_bias[i], devices_archetype[i]) \n",
        "               for i in range(NUM_DEVICES)]\n",
        "    print('Devices', len(devices))\n",
        "\n",
        "    start_time = time.time()\n",
        "    for round_num in range(NUM_ROUNDS):\n",
        "\n",
        "        if round_num >= THRESHOLD:\n",
        "            prune = True\n",
        "      \n",
        "        # select a percentage of devices to participate in each training round\n",
        "        round_devices = random.sample(devices, k=round(DEVICE_PCT*len(devices)))\n",
        "\n",
        "        for device in round_devices:\n",
        "            for model_id in model_id_lst:\n",
        "                if device.active[model_id] != 0:\n",
        "                    # Training\n",
        "                    for local_epoch in range(NUM_LOCAL_EPOCHS):\n",
        "                        train(local_epoch, device, model_id) \n",
        "                        # print(\"Device: \" + str(device.idx) + \" VALIDATION: model_id # \" + str(model_id))\n",
        "                        # validate(local_epoch, device, model_id) \n",
        "                        # print()\n",
        "                    # after training, quantize the learned model\n",
        "                    if QUANTIZE:\n",
        "                        quantize_model(device.nets[model_id]['net'], NBIT)\n",
        "            \n",
        "        for model_id in model_id_lst:\n",
        "            w_avg = model_average_weight(round_devices, model_id)\n",
        "\n",
        "            if w_avg != None:\n",
        "                for device in devices:\n",
        "                    if device.active[model_id]!= 0:\n",
        "                        device.nets[model_id]['net'].load_state_dict(w_avg)\n",
        "                        device.nets[model_id]['optimizer'].zero_grad()\n",
        "                        device.nets[model_id]['optimizer'].step()\n",
        "                        device.nets[model_id]['scheduler'].step()\n",
        "                \n",
        "            # test accuracy with highest ranking model\n",
        "            if devices[0].active[model_id] == 1 and devices[0].ranking[model_id] == max(devices[0].ranking):\n",
        "                # print()\n",
        "                # print(\"ALL-TEST ACCURACY\")\n",
        "                test(round_num, devices[0], model_id, arch_testset, test_dataloader)\n",
        "        \n",
        "        # Validation\n",
        "        if round_num not in DUPLICATE_MILESTONES:\n",
        "            for device in round_devices:\n",
        "                for model_id in model_id_lst:\n",
        "                    if device.active[model_id] != 0:\n",
        "                        validate(NUM_LOCAL_EPOCHS - 1, device, model_id)    # <- there are print statements here\n",
        "                # Figure out rankings here\n",
        "                device.update_ranking(prune)\n",
        "\n",
        "        # Testing with IID data from device\n",
        "        test_iid_results = []\n",
        "        for index in range(len(devices)):\n",
        "            device = devices[index]\n",
        "            max_model = device.ranking.index(max(device.ranking))\n",
        "            test_iid_results.append(float(test(round_num, device, max_model, device.device_testset, device.testloader)[1]))\n",
        "\n",
        "        print(round_num, test_iid_results)\n",
        "        tracker.update_per_device(test_iid_results)\n",
        "        \"\"\"\n",
        "        active_arr_tracker = [sum(devices[i].active) for i in range(len(devices))]\n",
        "        print(round_num, active_arr_tracker)\n",
        "        for i in range(len(devices)):\n",
        "            print(i, devices[i].ranking)\n",
        "            print(i, \" \", devices[i].ranking.index(max(devices[i].ranking)), \" \", devices[i].ranking)\n",
        "        \"\"\"\n",
        "\n",
        "        if algorithm == \"FedCD\" and round_num in DUPLICATE_MILESTONES:\n",
        "        # duplicate all models\n",
        "            # Run validation and update rankings for everyone\n",
        "            for device in devices:\n",
        "                for model_id in model_id_lst:\n",
        "                    if device.active[model_id] != 0:\n",
        "                        validate(NUM_LOCAL_EPOCHS - 1, device, model_id)    # <- there are print statements here\n",
        "                # Figure out rankings here\n",
        "                device.update_ranking(prune)\n",
        "\n",
        "            # Number of nets to duplicate\n",
        "            nets_to_create = len(model_id_lst)\n",
        "            for model_id in range(nets_to_create):\n",
        "                for device in devices:\n",
        "                    # If model wasn't already removed\n",
        "                    if device.active[model_id] != 0:    \n",
        "                        device_net = ConvNet().cuda()\n",
        "                        device_net.load_state_dict(device.nets[model_id]['net'].state_dict())\n",
        "                        valid_loss_tracker = [copy.deepcopy(device.nets[model_id]['valid_loss_tracker'][-1])]\n",
        "                        valid_acc_tracker = [100 - copy.deepcopy(device.nets[model_id]['valid_acc_tracker'][-1])]\n",
        "                        optimizer = torch.optim.SGD(device_net.parameters(), lr=0.1, momentum=0.9,\n",
        "                                                    weight_decay=5e-4)\n",
        "                        rounds_passed = len(device.nets[model_id]['train_acc_tracker'])\n",
        "                        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                                        milestones=[25-rounds_passed, 50-rounds_passed, 75-rounds_passed],\n",
        "                                                                        gamma=0.1)\n",
        "                        device.nets.append({\n",
        "                            'net': device_net,\n",
        "                            'optimizer': optimizer,\n",
        "                            'scheduler': scheduler,\n",
        "                            'train_loss_tracker': [],\n",
        "                            'train_acc_tracker': [],\n",
        "                            'valid_loss_tracker': valid_loss_tracker,\n",
        "                            'valid_acc_tracker': valid_acc_tracker,\n",
        "                            'test_loss_tracker': [],\n",
        "                            'test_acc_tracker': [],\n",
        "                        })\n",
        "                        device.active.append(1)\n",
        "                        # Heavily rank the devices that are underperforming for new models and vice versa\n",
        "                        if len(valid_acc_tracker) > 0:\n",
        "                            device.update_ranking(prune, removed = False, duplicate_model_id = model_id + nets_to_create, offset_rank = valid_acc_tracker[-1])\n",
        "                        else:\n",
        "                            device.update_ranking(prune)\n",
        "                    # If model was already removed\n",
        "                    else:                           \n",
        "                        device.nets.append({\n",
        "                            'valid_acc_tracker': [0.],\n",
        "                        })\n",
        "                        device.active.append(0)\n",
        "                        device.update_ranking(prune, removed = True, duplicate_model_id = model_id + nets_to_create)\n",
        "\n",
        "                model_id_lst.append(model_id + nets_to_create)\n",
        "        # print('model id list:', model_id_lst)\n",
        "        # print('best model:', [device.ranking.index(max(device.ranking)) for device in devices])\n",
        "        # for device in devices:\n",
        "            # print(\"device's active models:\", device.active)\n",
        "            # print(\"device \" + str(device.idx) + \" ranking: \" + str(device.ranking))\n",
        "            # print(\"archetype:\", device.archetype)\n",
        "\n",
        "        # TODO save both print after\n",
        "\t\n",
        "    total_time = time.time() - start_time\n",
        "    print('Total training time: {} seconds'.format(total_time))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtkYyNF5Oo9J"
      },
      "source": [
        "---\n",
        "###**Run Experiment**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2SEX0tHt_4J",
        "outputId": "48f76a63-dfe1-43cc-bec8-412ea2160f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# load training and validation data from CIFAR-10\n",
        "transform_train_valid = transforms.Compose([                                   \n",
        "    transforms.RandomCrop(32, padding=4),                                       \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True,\n",
        "                                        transform=transform_train_valid)\n",
        "validset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True,\n",
        "                                        transform=transform_train_valid)\n",
        "\n",
        "# fraction of data reserved for validation\n",
        "valid_fraction = 0.2\n",
        "indices = list(range(len(trainset)))\n",
        "split = int(np.floor(valid_fraction * len(trainset)))\n",
        "    \n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, \n",
        "                                            sampler=valid_sampler, shuffle=False,\n",
        "                                            num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=128, \n",
        "                                            sampler=valid_sampler, shuffle=False,\n",
        "                                            num_workers=2)\n",
        "# load testing data\n",
        "transform_test = transforms.Compose([                                           \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKogIgMUgE0f"
      },
      "source": [
        "# Train model on each device\n",
        "# Get rankings on each device\n",
        "# Update weights\n",
        "\n",
        "net = ConvNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "devices_archetype = [[i//3] for i in range(NUM_DEVICES)]\n",
        "devices_bias = [random.uniform(0.6, 0.7) for i in range(NUM_DEVICES)]\n",
        "\n",
        "train_idxs = data_sampler(DISTRIBUTION, trainset, NUM_TRAIN_PER_DEVICE, devices_archetype, devices_bias)\n",
        "valid_idxs = data_sampler(DISTRIBUTION, validset, NUM_VALID_PER_DEVICE, devices_archetype, devices_bias)\n",
        "test_idxs_device = data_sampler(DISTRIBUTION, testset, NUM_TEST_PER_DEVICE, devices_archetype, devices_bias)\n",
        "\n",
        "label_dict_test = gen_label_dict(testset)\n",
        "test_idxs = [id for i in range(NUM_LABELS) for id in label_dict_test[i]]\n",
        "random.shuffle(test_idxs)\n",
        "\n",
        "arch_testset = DatasetSplit(testset, test_idxs)\n",
        "test_dataloader = torch.utils.data.DataLoader(arch_testset, batch_size=128,\n",
        "                                                shuffle=True, num_workers=2)\n",
        "\n",
        "label_dict_valid = gen_label_dict(validset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LQCWEsek5Tz",
        "outputId": "13fc7a08-5165-4d92-e02a-4d4f72063419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "source": [
        "# FedCD: Federated Cloning and Deletion\n",
        "if RUN_FEDCD:\n",
        "    federated_learning(\"FedCD\")\n",
        "\n",
        "# FedAvg: Federated Learning Baseline\n",
        "if RUN_FEDAVG:\n",
        "    federated_learning(\"FedAvg\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Devices 30\n",
            "0 [8.0, 10.0, 9.6, 10.4, 7.6, 11.0, 8.6, 9.0, 9.4, 64.0, 68.8, 9.0, 7.4, 9.0, 7.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "1 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 62.0, 58.8, 69.0, 40.2, 9.0, 10.2, 10.2, 61.4, 68.0, 7.2, 13.2, 10.2, 8.0, 8.6, 14.2]\n",
            "2 [15.2, 69.2, 13.2, 46.0, 47.4, 44.4, 28.8, 61.8, 55.8, 11.0, 9.2, 14.8, 11.4, 11.4, 12.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "3 [0.0, 62.0, 53.4, 58.8, 64.6, 55.4, 68.8, 70.2, 70.6, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 61.6, 47.6, 57.6, 76.6, 75.4, 75.2, 45.6, 44.4, 41.0, 67.8, 66.8, 67.8, 41.6, 47.6, 53.2]\n",
            "4 [0.0, 69.2, 66.0, 61.0, 65.2, 62.4, 62.4, 40.6, 53.4, 0.0, 61.6, 60.8, 0.0, 30.6, 0.0, 66.4, 54.8, 54.8, 83.6, 84.2, 75.2, 71.8, 69.8, 64.6, 81.4, 80.4, 77.8, 65.2, 68.2, 54.6]\n",
            "5 [67.8, 69.0, 73.2, 76.0, 78.2, 74.8, 55.8, 33.8, 46.8, 12.2, 47.4, 55.2, 44.8, 45.4, 40.2, 61.8, 61.2, 68.8, 27.8, 39.8, 24.8, 37.4, 48.2, 0.0, 23.8, 31.0, 23.2, 24.6, 28.2, 29.6]\n",
            "6 [63.0, 58.2, 64.6, 77.2, 80.2, 78.2, 53.6, 59.2, 62.8, 60.6, 50.4, 58.2, 44.2, 61.4, 34.0, 37.4, 32.0, 39.0, 37.2, 48.2, 33.8, 52.0, 52.4, 0.0, 65.8, 71.2, 60.0, 60.6, 50.4, 57.2]\n",
            "7 [72.2, 75.6, 72.4, 73.2, 78.2, 74.0, 61.0, 65.8, 62.4, 62.6, 44.8, 60.0, 0.0, 63.2, 0.0, 83.2, 83.0, 82.6, 83.8, 84.8, 84.0, 74.4, 69.0, 71.8, 80.2, 81.4, 81.6, 84.0, 83.2, 81.2]\n",
            "8 [68.6, 74.0, 73.0, 77.0, 80.6, 79.8, 52.4, 55.8, 51.2, 72.0, 58.0, 73.8, 0.0, 73.8, 0.0, 74.2, 81.6, 82.0, 84.6, 87.2, 89.0, 80.8, 72.8, 76.6, 87.0, 82.0, 86.8, 84.4, 60.6, 85.8]\n",
            "9 [69.6, 73.6, 71.2, 80.2, 84.8, 81.0, 64.8, 64.8, 62.2, 43.6, 62.8, 74.4, 0.0, 68.6, 0.0, 79.6, 68.4, 87.2, 81.2, 79.8, 83.6, 85.2, 82.6, 75.2, 86.4, 83.8, 85.4, 79.6, 53.2, 79.4]\n",
            "10 [70.6, 75.8, 70.6, 82.6, 85.0, 82.6, 65.2, 66.8, 67.2, 73.8, 70.2, 77.4, 0.0, 61.0, 65.8, 82.8, 65.4, 87.2, 86.4, 85.0, 85.2, 84.0, 82.4, 74.6, 91.4, 88.0, 91.0, 84.8, 85.6, 85.6]\n",
            "11 [68.2, 72.4, 66.8, 82.4, 83.0, 83.8, 72.2, 76.6, 72.0, 60.0, 56.6, 66.6, 70.2, 68.2, 74.4, 79.2, 81.8, 87.8, 87.8, 86.6, 85.2, 81.6, 57.4, 68.2, 87.8, 86.8, 91.2, 82.8, 82.6, 85.4]\n",
            "12 [75.4, 78.8, 74.6, 78.6, 80.6, 79.6, 74.8, 76.0, 74.4, 74.0, 61.0, 64.6, 66.4, 65.8, 55.6, 83.6, 83.8, 90.0, 91.2, 88.8, 87.6, 85.6, 67.8, 81.4, 90.2, 90.6, 91.4, 88.2, 83.6, 87.0]\n",
            "13 [75.2, 84.4, 80.8, 86.4, 88.4, 84.2, 59.4, 71.4, 64.6, 73.6, 73.4, 71.6, 78.2, 77.6, 74.8, 68.2, 78.6, 82.4, 91.4, 88.6, 89.8, 90.4, 85.2, 85.6, 94.0, 90.2, 93.6, 86.4, 80.4, 86.8]\n",
            "14 [76.4, 74.6, 75.6, 85.0, 87.0, 84.0, 77.4, 75.0, 76.6, 77.2, 72.8, 77.2, 73.4, 73.0, 76.2, 73.4, 75.0, 70.4, 94.0, 90.0, 91.8, 83.2, 79.6, 81.2, 90.4, 87.6, 90.0, 88.2, 86.4, 90.4]\n",
            "15 [72.4, 74.8, 77.2, 82.6, 81.2, 82.6, 73.0, 76.8, 67.4, 78.2, 74.6, 69.4, 77.6, 77.6, 67.4, 78.2, 81.2, 86.2, 93.2, 91.4, 94.0, 83.8, 85.0, 85.6, 89.0, 87.8, 90.2, 92.2, 90.8, 90.0]\n",
            "16 [81.6, 82.8, 77.8, 84.8, 89.4, 87.0, 72.2, 75.8, 79.8, 46.8, 80.6, 81.6, 73.6, 74.4, 67.6, 85.0, 86.4, 89.2, 92.4, 92.2, 83.6, 90.8, 88.2, 86.6, 89.6, 90.4, 89.6, 92.4, 90.6, 89.6]\n",
            "17 [73.0, 76.8, 73.0, 88.2, 90.6, 86.8, 81.0, 82.8, 82.4, 84.0, 77.2, 77.2, 58.2, 67.4, 70.6, 88.2, 88.0, 89.6, 88.2, 90.4, 90.8, 81.2, 82.0, 82.8, 89.8, 89.2, 89.4, 85.4, 86.0, 86.2]\n",
            "18 [85.6, 84.8, 87.2, 88.6, 91.8, 87.6, 77.6, 72.8, 78.6, 77.6, 76.4, 80.4, 87.6, 86.4, 86.2, 83.6, 89.4, 92.0, 93.0, 91.6, 93.2, 86.2, 87.0, 84.6, 93.4, 90.8, 89.6, 88.6, 87.4, 90.2]\n",
            "19 [80.8, 78.8, 84.6, 89.6, 92.8, 89.8, 79.8, 75.0, 78.8, 83.0, 80.2, 81.6, 82.2, 75.6, 76.2, 81.2, 84.4, 90.4, 91.8, 93.0, 93.0, 84.0, 81.8, 79.8, 94.4, 93.6, 89.6, 90.4, 91.4, 91.2]\n",
            "20 [80.2, 79.2, 85.2, 88.4, 92.6, 89.4, 84.6, 81.2, 70.8, 84.0, 79.4, 78.8, 85.4, 69.8, 71.4, 90.8, 88.8, 89.0, 92.0, 90.2, 91.0, 83.6, 81.6, 80.4, 86.6, 88.6, 81.6, 89.6, 89.0, 91.0]\n",
            "21 [80.4, 82.0, 79.6, 86.0, 90.2, 88.6, 71.4, 65.4, 73.6, 86.8, 87.2, 86.6, 84.0, 71.8, 77.4, 89.8, 89.6, 88.0, 88.4, 91.4, 93.8, 88.6, 86.4, 86.8, 91.2, 91.0, 88.2, 87.8, 87.6, 89.8]\n",
            "22 [81.4, 81.8, 82.8, 89.6, 92.6, 89.8, 66.4, 80.2, 80.8, 79.4, 69.2, 83.0, 89.2, 85.2, 86.8, 86.2, 87.6, 88.4, 94.2, 91.4, 94.2, 93.2, 91.2, 91.6, 95.0, 95.0, 93.8, 92.4, 91.6, 94.4]\n",
            "23 [81.6, 80.0, 82.8, 90.2, 93.6, 90.2, 63.0, 74.0, 75.6, 78.0, 74.4, 82.0, 79.8, 88.8, 93.2, 87.4, 88.4, 90.4, 94.0, 92.6, 94.2, 89.6, 87.4, 85.6, 94.6, 94.2, 94.4, 91.4, 90.0, 93.2]\n",
            "24 [81.0, 77.2, 73.2, 87.6, 93.2, 92.8, 86.4, 77.2, 83.8, 83.2, 83.2, 85.8, 74.4, 86.0, 84.2, 88.8, 90.0, 91.2, 95.2, 91.0, 94.4, 92.2, 89.0, 87.6, 95.4, 95.0, 95.0, 94.4, 94.6, 94.2]\n",
            "25 [88.4, 86.6, 88.4, 93.0, 95.0, 94.0, 86.4, 81.6, 82.8, 86.8, 85.2, 86.0, 82.8, 85.4, 87.4, 89.4, 89.4, 90.4, 94.4, 93.2, 94.2, 94.4, 91.2, 90.0, 94.2, 94.4, 95.0, 95.6, 94.8, 95.2]\n",
            "26 [87.8, 87.0, 87.0, 93.6, 95.4, 93.8, 87.8, 84.6, 84.2, 84.6, 82.0, 84.8, 86.6, 84.8, 83.4, 91.0, 91.0, 93.4, 93.0, 87.8, 93.8, 92.6, 90.0, 88.0, 95.4, 95.0, 95.8, 95.0, 93.6, 94.6]\n",
            "27 [88.6, 88.4, 86.8, 93.6, 95.4, 93.6, 86.4, 82.6, 85.2, 88.2, 85.8, 86.4, 87.0, 85.2, 75.0, 86.0, 87.8, 87.8, 95.6, 94.4, 94.8, 93.8, 92.2, 90.0, 95.2, 95.2, 95.4, 93.6, 92.0, 94.4]\n",
            "28 [91.2, 90.4, 91.2, 92.2, 95.6, 93.2, 84.4, 81.8, 82.8, 87.4, 85.2, 86.2, 87.4, 85.8, 87.2, 89.0, 91.2, 92.0, 94.6, 94.2, 94.6, 93.6, 92.2, 89.4, 96.0, 95.8, 96.4, 94.8, 93.8, 94.8]\n",
            "29 [89.6, 87.8, 90.2, 93.8, 96.2, 94.2, 85.4, 80.8, 81.8, 84.4, 82.4, 85.0, 90.0, 89.8, 91.4, 88.6, 91.8, 91.4, 95.6, 93.8, 95.2, 94.4, 92.2, 90.2, 95.6, 95.6, 96.0, 96.6, 95.4, 95.4]\n",
            "30 [90.8, 89.6, 67.2, 93.4, 96.4, 94.2, 83.4, 79.6, 80.0, 88.2, 85.6, 86.6, 88.6, 87.6, 43.0, 90.2, 91.8, 91.0, 95.4, 94.2, 95.2, 94.6, 92.4, 91.8, 95.6, 95.8, 96.2, 96.8, 94.6, 95.2]\n",
            "31 [89.8, 90.6, 91.4, 92.8, 96.4, 93.8, 84.2, 79.6, 83.8, 88.4, 86.6, 87.8, 89.2, 87.6, 88.0, 88.6, 89.8, 89.8, 95.4, 94.8, 95.4, 94.0, 91.8, 91.2, 96.0, 96.2, 96.2, 95.0, 93.4, 94.6]\n",
            "32 [88.6, 87.6, 89.2, 94.2, 96.6, 95.6, 87.8, 84.0, 85.8, 86.8, 86.2, 86.4, 89.4, 88.6, 89.0, 89.0, 90.2, 90.8, 95.4, 94.0, 94.6, 93.8, 90.6, 90.0, 95.4, 95.8, 95.6, 96.6, 95.2, 96.2]\n",
            "33 [87.8, 87.4, 89.0, 94.2, 96.2, 95.2, 88.8, 85.6, 84.8, 86.6, 86.0, 87.0, 86.8, 86.4, 87.4, 92.0, 92.2, 94.4, 94.8, 92.6, 93.8, 93.0, 90.8, 88.6, 95.6, 96.2, 95.2, 96.0, 94.6, 95.6]\n",
            "34 [91.4, 89.6, 91.8, 94.0, 96.6, 95.2, 84.4, 83.0, 84.8, 86.6, 85.4, 86.6, 89.0, 88.2, 90.8, 89.0, 91.0, 92.0, 94.0, 93.6, 94.2, 93.8, 92.2, 91.8, 96.6, 97.0, 96.6, 94.6, 93.8, 94.8]\n",
            "35 [92.0, 91.2, 93.4, 92.2, 95.2, 94.0, 88.0, 82.6, 83.6, 85.0, 82.6, 84.2, 88.2, 87.0, 88.6, 90.2, 89.8, 91.6, 94.4, 93.2, 94.4, 95.8, 93.2, 92.8, 95.8, 96.8, 96.2, 95.8, 94.8, 95.8]\n",
            "36 [91.2, 89.0, 91.8, 92.8, 96.0, 93.8, 86.2, 82.4, 85.4, 87.8, 86.2, 81.8, 91.0, 89.8, 90.4, 90.4, 91.4, 92.6, 94.0, 93.4, 94.2, 92.4, 91.2, 89.8, 96.6, 95.8, 96.8, 94.4, 94.0, 95.0]\n",
            "37 [91.4, 90.2, 88.4, 93.4, 96.8, 94.4, 84.4, 82.6, 84.2, 89.8, 87.4, 88.6, 87.4, 88.2, 89.0, 91.0, 90.0, 91.4, 95.8, 95.2, 95.4, 95.0, 90.8, 90.8, 96.2, 96.6, 96.8, 95.2, 94.6, 94.8]\n",
            "38 [88.6, 87.0, 89.0, 94.0, 97.0, 94.6, 85.2, 82.0, 84.8, 88.6, 88.8, 80.4, 92.0, 89.2, 88.0, 91.8, 91.2, 92.4, 95.8, 94.0, 94.2, 94.4, 92.6, 91.8, 96.8, 96.0, 96.6, 95.8, 94.8, 95.6]\n",
            "39 [90.2, 87.8, 93.2, 92.8, 96.8, 95.4, 88.2, 84.2, 86.0, 85.4, 84.4, 85.6, 88.2, 89.4, 91.4, 90.0, 91.2, 90.8, 96.0, 95.0, 95.4, 95.0, 92.2, 91.8, 96.8, 95.6, 96.4, 95.4, 95.0, 96.0]\n",
            "40 [90.8, 91.4, 83.0, 94.0, 97.2, 94.8, 87.0, 83.0, 84.6, 89.6, 88.6, 88.8, 82.4, 88.6, 88.4, 93.0, 92.8, 93.8, 95.6, 94.0, 95.0, 94.0, 92.0, 91.6, 97.0, 96.2, 96.4, 96.8, 94.8, 96.2]\n",
            "41 [92.2, 90.6, 88.8, 93.0, 95.8, 94.0, 86.4, 81.4, 83.4, 89.0, 86.6, 87.8, 91.2, 89.6, 89.8, 92.8, 91.0, 92.4, 95.8, 94.0, 94.0, 96.0, 93.8, 92.4, 96.6, 96.4, 96.8, 96.2, 95.6, 95.4]\n",
            "42 [90.0, 90.2, 92.2, 93.6, 96.4, 94.8, 88.8, 83.0, 85.2, 91.0, 89.2, 88.8, 88.2, 87.8, 87.6, 91.6, 90.8, 92.6, 96.0, 95.6, 95.2, 95.2, 92.8, 92.4, 97.0, 95.6, 96.6, 96.2, 95.6, 95.8]\n",
            "43 [91.2, 90.2, 92.4, 93.0, 96.6, 95.2, 79.0, 86.0, 85.6, 87.0, 85.0, 88.6, 90.6, 90.0, 90.2, 91.8, 90.4, 91.2, 95.4, 94.6, 94.8, 95.0, 91.6, 92.2, 97.2, 95.6, 96.2, 95.8, 94.2, 94.8]\n",
            "44 [89.6, 88.6, 91.6, 93.8, 96.6, 95.2, 89.4, 85.8, 85.8, 88.4, 86.6, 87.6, 87.0, 90.6, 91.0, 92.2, 91.0, 92.2, 95.6, 94.2, 94.4, 95.4, 92.4, 93.2, 96.8, 96.0, 96.2, 95.6, 94.6, 94.8]\n",
            "45 [91.6, 88.8, 91.0, 93.6, 97.2, 95.8, 87.4, 85.4, 86.6, 85.2, 84.0, 86.4, 91.0, 90.6, 92.4, 92.8, 91.8, 93.4, 95.4, 94.8, 95.0, 94.8, 91.4, 92.4, 96.2, 96.0, 96.4, 96.4, 96.4, 96.0]\n",
            "46 [90.2, 88.4, 90.4, 93.8, 96.6, 95.0, 75.4, 82.4, 85.6, 90.0, 89.6, 89.2, 91.4, 90.0, 89.8, 91.8, 92.0, 92.4, 96.0, 95.0, 95.6, 94.2, 91.4, 91.8, 96.8, 96.0, 96.4, 96.6, 95.4, 95.8]\n",
            "47 [89.4, 89.8, 92.0, 93.6, 97.8, 95.4, 90.4, 86.4, 88.2, 87.8, 87.0, 86.8, 91.2, 90.4, 89.6, 91.2, 90.4, 92.4, 95.6, 94.8, 94.2, 94.6, 92.0, 91.8, 96.0, 95.4, 95.2, 96.8, 96.4, 96.0]\n",
            "48 [90.2, 89.2, 92.0, 93.8, 97.0, 95.2, 88.6, 81.8, 86.8, 90.8, 89.0, 89.4, 89.4, 89.0, 88.8, 92.2, 91.0, 93.2, 95.8, 94.6, 94.4, 95.8, 94.2, 94.4, 96.4, 95.8, 95.8, 97.2, 95.8, 95.6]\n",
            "49 [89.8, 88.4, 92.0, 94.2, 97.0, 96.0, 90.0, 85.6, 86.2, 88.6, 87.8, 88.0, 92.8, 91.2, 92.4, 90.6, 90.4, 92.2, 95.6, 95.0, 96.0, 94.2, 91.2, 91.6, 95.0, 95.6, 94.8, 96.4, 96.2, 96.4]\n",
            "50 [89.2, 87.2, 90.4, 94.2, 96.6, 95.4, 85.6, 85.6, 84.2, 85.4, 88.0, 88.0, 91.2, 90.8, 90.0, 91.6, 91.6, 93.6, 95.6, 94.4, 94.0, 95.0, 92.2, 92.2, 96.4, 96.0, 95.4, 96.2, 95.8, 96.0]\n",
            "51 [88.6, 87.4, 89.6, 93.6, 96.4, 95.2, 86.6, 86.0, 86.8, 85.2, 85.6, 87.6, 92.4, 91.4, 92.6, 93.2, 92.6, 95.0, 96.0, 93.8, 94.4, 93.8, 92.2, 91.6, 96.2, 95.6, 96.6, 97.6, 96.0, 95.8]\n",
            "52 [90.0, 88.2, 91.4, 93.8, 96.8, 95.6, 87.2, 85.6, 86.6, 87.2, 89.2, 89.2, 92.4, 92.6, 91.8, 92.8, 92.2, 94.4, 95.2, 94.0, 94.4, 94.4, 93.0, 92.0, 96.4, 95.4, 96.2, 96.8, 96.2, 95.8]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}